{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3da50-6cf1-4943-b31f-cb9fc7815a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import copy\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61415c5-dc1e-4f84-91bc-f4c1fafd36fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_batch_size,test_batch_size):\n",
    "    # Fetch training data: total 60000 samples\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.MNIST('data', train=True, download=True,\n",
    "                       transform=transforms.Compose([ transforms.ToTensor()  ])),\n",
    "        batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "    # Fetch test data: total 10000 samples\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.MNIST('data', train=False, transform=transforms.Compose([transforms.ToTensor() ])),\n",
    "        batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "    return (train_loader,test_loader)\n",
    "train_batch_size = 1000\n",
    "test_batch_size = 1000\n",
    "train_loader, test_loader = load_data(train_batch_size, test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a30987-652e-4ee9-aa3e-27f06b086b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.fc2 = nn.Linear(500, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4e1f56-043e-450f-8828-f2fa98d7511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68716d2-6a8e-4978-bdc0-b35f244206ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_Losses(model, loader):\n",
    "    correct_class = 0\n",
    "    totalVal = 0\n",
    "    costTotal = 0\n",
    "    costCounter = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            img, target = batch\n",
    "            output = model(img.view(-1, 784))\n",
    "            cost = loss_function(output, target)\n",
    "            costTotal += cost\n",
    "            costCounter += 1\n",
    "            for i, outputTensor in enumerate(output):\n",
    "                if torch.argmax(outputTensor) == target[i]:\n",
    "                    correct_class += 1\n",
    "                totalVal += 1\n",
    "    return costTotal / costCounter, round(correct_class/totalVal, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcef383-1ae3-485c-8ffb-b1beefac8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss1 = []\n",
    "test_loss1 = []\n",
    "train_acc1 = []\n",
    "test_acc1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba3f31-b2db-4e30-bc4d-d569b79634c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, number_epochs):\n",
    "\n",
    "    model.train()\n",
    "    epoch = 0\n",
    "    dataf = pd.DataFrame()\n",
    "\n",
    "    for epoch in range (number_epochs):\n",
    "        epoch += 1\n",
    "\n",
    "        for _, (imgs, targets) in enumerate(train_loader):\n",
    "            imgs, targets = Variable(imgs),Variable(targets)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(imgs.view(-1, 784))\n",
    "            loss = loss_function(prediction, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        temp_dataf = pd.DataFrame()\n",
    "        #if(epoch%3==0):\n",
    "            \n",
    "        for name, parameter in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    weights = torch.nn.utils.parameters_to_vector(parameter).detach().numpy()\n",
    "                    temp_dataf = pd.concat([temp_dataf, pd.DataFrame(weights).T], axis = 1)\n",
    "        dataf = pd.concat([dataf, temp_dataf], axis = 0)\n",
    "        train_loss, train_acc = Calculate_Losses(Model_1, train_loader)\n",
    "        test_loss, test_acc = Calculate_Losses(Model_1, test_loader)\n",
    "\n",
    "        train_loss1.append(train_loss)\n",
    "        test_loss1.append(test_loss)\n",
    "        train_acc1.append(train_acc)\n",
    "        test_acc1.append(test_acc)\n",
    "\n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57db41-86e6-426f-953a-f473cd466c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 45\n",
    "all_dataf = pd.DataFrame()\n",
    "columns=[\"x\",\"y\",\"Repetition\"]\n",
    "\n",
    "#loss_fn = nn.CrossEntropyLoss()\n",
    "for count in range(8):\n",
    "    print(\"Repetition: \"+str(count))\n",
    "    Model_1 = Model()\n",
    "    optimizer = torch.optim.Adam(Model_1.parameters(),lr = 0.001, weight_decay=1e-4)\n",
    "    model_name1 = \"Repetition: \"+str(count)\n",
    "    temp_dataf = train(Model_1, max_epochs)\n",
    "    \n",
    "    all_dataf = pd.concat([all_dataf,temp_dataf],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a6051-7c2d-4ad3-9768-56281ceeae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf=all_dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae8e81-d5bb-4ff5-b719-40517bf40009",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf=np.array(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a0dea-85bb-4dd9-8c30-5e2868677c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682d279-86cc-482c-8ce6-6c64f2e1ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_data=pca.fit_transform(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55daf4f-b6ad-48d1-89a1-7e7c9f29bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length of train_acc1: {len(train_acc1)}\")\n",
    "print(f\"Length of dataf: {len(dataf)}\")\n",
    "print(f\"Length of train_acc1: {len(train_loss1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376b6c1-d5b1-45fa-8fe2-e2ed20ab231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = pd.DataFrame(smaller_data, columns=['x','y'])\n",
    "dataf['Accuracy'] = train_acc1\n",
    "temp_dataf['Accuracy'] = train_acc1[:len(temp_dataf)]\n",
    "dataf['Loss'] = train_loss1\n",
    "final_dataf = dataf.iloc[::3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53497019-41f8-4a75-ba54-21066cd974c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(120):\n",
    "    m = list(final_dataf['Accuracy'])[i]\n",
    "    plt.scatter(final_dataf['x'][i*3], final_dataf['y'][i*3], marker = f'${m}$')\n",
    "    plt.title(\"PCA for model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e237c6-a901-44f9-974c-b5b6be630991",
   "metadata": {},
   "outputs": [],
   "source": [
    "level1 = all_dataf.iloc[ : , 0:7840]\n",
    "dataf = level1\n",
    "dataf = np.array(df)\n",
    "pca = PCA(n_components=2)\n",
    "smaller_data = pca.fit_transform(dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6281ef-1b1c-4c34-a566-9d6975ae7271",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(120):\n",
    "    m = list(final_dataf['Accuracy'])[i]\n",
    "    plt.scatter(final_dataf['x'][i*3], final_dataf['y'][i*3], marker = f'${m}$')\n",
    "    plt.title(\"PCA for Layer 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca5d80-a7ed-4ad4-a3ff-ab8650549fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
